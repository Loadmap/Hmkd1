{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b3d44d",
   "metadata": {},
   "source": [
    "### API (Application Programming Interface)\n",
    "API란 웹 상에서 데이터를 주고받을 수 있도록 미리 정해진 규칙과 프로토콜을 제공하는 인터페이스입니다. 인공지능 개발자는 이러한 API를 통해 데이터를 쉽게 수집하고 활용할 수 있습니다.\n",
    "\n",
    "날씨 정보, 지리 정보, 주가 정보, 소셜 미디어 데이터 등 다양한 데이터를 API를 통해 수집할 수 있습니다. 이렇게 수집한 데이터를 기반으로 인공지능 모델을 학습시키고 예측 모델을 구축할 수 있습니다.\n",
    "\n",
    "API를 사용하면 데이터를 실시간으로 수집하는 것도 가능합니다. 데이터 분석가나 인공지능 개발자는 API를 통해 빠르게 변화하는 데이터를 수집하고, 이를 바탕으로 인공지능 모델을 최신화하고 새로운 트렌드에 대응할 수 있습니다.\n",
    "\n",
    "또한, 데이터를 가공하거나 필요한 부분만 추출할 수도 있습니다. 이를 통해 인공지능 개발자는 필요한 데이터만 추출하고 이를 활용하여 모델을 더욱 효과적으로 구성할 수 있습니다.\n",
    "\n",
    "이러한 API를 활용한 데이터 수집은 파이썬에서도 쉽게 구현할 수 있습니다. requests 라이브러리를 이용하여 API를 호출하고, JSON 또는 XML과 같은 형식으로 데이터를 수집하고 가공할 수 있습니다.\n",
    "\n",
    "image.png\n",
    "\n",
    "https://cs-fundamentals.blogspot.com/2020/06/basic-api-development-part-1-importance.html\n",
    "\n",
    "Naver API\n",
    "https://developers.naver.com/main/\n",
    "\n",
    "네이버 API는 네이버에서 제공하는 다양한 서비스들을 이용할 수 있도록 제공하는 API입니다. 네이버 블로그 검색, 지식인 검색, 뉴스 검색 등의 기능을 API를 통해 사용할 수 있습니다. 이를 이용하여 웹 애플리케이션, 모바일 애플리케이션 등 다양한 서비스를 개발할 수 있습니다.\n",
    "\n",
    "[사용방법]\n",
    "\n",
    "네이버 개발자 센터에서 애플리케이션을 등록하고 클라이언트 아이디와 클라이언트 시크릿을 발급\n",
    "애플리케이션에 사용할 네이버 오픈API를 사용 API에서 선택해 추가\n",
    "로그인 오픈 API 서비스 환경별 상세 정보는 로그인 오픈 API 서비스 환경에서 입력\n",
    "네이버 오픈API는 인증 여부에 따라 로그인 방식 오픈 API와 비로그인 방식 오픈 API로 구분됩니다. 로그인 방식 오픈 API는 '네이버 로그인’의 인증을 받아 접근 토큰(access token)을 획득해야 사용할 수 있는 오픈 API입니다. API를 호출할 때 네이버 로그인 API를 통해 받은 접근 토큰의 값을 전송해야 합니다\n",
    "\n",
    "https://seo.tbwakorea.com/blog/naver-seo-api-searching-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 검색 API 예제 - 블로그 검색\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "# client_id와 client_secret 변수에는 네이버에서 제공하는 클라이언트 ID와 클라이언트 시크릿 값이 저장\n",
    "client_id = \"YOUR_CLIENT_ID\"\n",
    "client_secret = \"YOUR_CLIENT_SECRET\"\n",
    "# urllib.parse.quote() 함수를 사용하여 검색어에 대한 URL 인코딩을 수행\n",
    "encText = urllib.parse.quote(\"검색할 단어\")\n",
    "# url 변수에는 검색어를 포함한 검색 API의 URL이 저장되어 있습니다. 이때 검색 결과 형식을 JSON or XML로 설정\n",
    "url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # JSON 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # XML 결과\n",
    "\n",
    "# urllib.request.Request() 함수를 사용하여 API에 대한 요청(Request) 객체를 생성\n",
    "request = urllib.request.Request(url)\n",
    "# add_header() 함수를 사용하여 클라이언트 ID와 클라이언트 시크릿 값을 요청 헤더에 포함\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "# urllib.request.urlopen() 함수를 사용하여 요청 객체를 전송하고, API에서 반환한 응답(Response) 객체를 받아옴\n",
    "response = urllib.request.urlopen(request)\n",
    "# response.getcode() 함수를 사용하여 HTTP 응답 코드를 확인\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    # response_body.decode('utf-8') 함수를 사용하여 문자열 형태로 디코딩\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85989f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response_body' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13264\\2591865307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mxml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response_body' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "xml = response_body.decode('utf-8')\n",
    "bs = BeautifulSoup(xml,'lxml')\n",
    "bs.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "texts = str(bs)\n",
    "# texts = re.sub(r'<[^>]*>','',texts)\n",
    "texts = re.sub(r'<.*?>','',texts) # <.*?> 패턴은 꺽쇠 괄호 사이에 있는 최소한의 문자열을 매칭시키는 패턴\n",
    "texts = re.findall(r'[a-zA-Z0-9가-힣]+', texts)\n",
    "print(' '.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "client_id = \"xUCzXK76sez26412vcLf\"\n",
    "client_secret = \"oCZNcdIe3A\"\n",
    "query = urllib.parse.quote(input('검색 질의 : '))\n",
    "\n",
    "url = \"https://openapi.naver.com/v1/search/webkr?query=\" + query # json 결과\n",
    "\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "idx =0\n",
    "web_df = pd.DataFrame(columns=('title','link','description'))\n",
    "\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    response_dict = json.loads(response_body.decode('utf-8'))\n",
    "    \n",
    "    items = response_dict['items']\n",
    "    \n",
    "    for item_index in range(0,len(items)):\n",
    "        remove_tag = re.compile('<.*?>')\n",
    "        title = re.sub(remove_tag, \"\", items[item_index]['title'])\n",
    "        link = items[item_index]['link']\n",
    "        description = re.sub(remove_tag, '',items[item_index]['description'] )\n",
    "        web_df.loc[idx] = [title, link, description]\n",
    "        idx += 1\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "    \n",
    "web_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "client_id = \"xUCzXK76sez26412vcLf\"\n",
    "client_secret = \"oCZNcdIe3A\"\n",
    "\n",
    "query = urllib.parse.quote(input(\"검색 질의: \"))\n",
    "# encText = urllib.parse.quote(\"빅데이터\") # utf-8 형태로 인코딩\n",
    "idx = 0\n",
    "display = 100\n",
    "start = 1\n",
    "end = 1000\n",
    "\n",
    "web_df = pd.DataFrame(columns=('Datetime','Title','Link','Description'))\n",
    "\n",
    "# for 문을 사용하여 검색 결과를 한 번에 display개씩 가져오는 것을 반복하며, \n",
    "# start_index 변수에는 현재 검색 결과 중 첫 번째 인덱스가 저장\n",
    "for start_index in range(start, end, display):\n",
    "    \n",
    "# url 변수에는 검색어와 검색 결과 개수, 시작 인덱스 등이 포함된 검색 API의 URL이 저장\n",
    "    url = \"https://openapi.naver.com/v1/search/webkr?query=\" + query \\\n",
    "    + \"&display=\" + str(display) \\\n",
    "    + \"&start=\" + str(start_index)\n",
    "     \n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        response_dict = json.loads(response_body.decode('utf-8'))\n",
    "        # response_dict에서 items 키 값을 추출하고, 이를 반복하며 title, link, description 등의 정보를 추출\n",
    "        items = response_dict['items']\n",
    "        \n",
    "        for item_index in range(0,len(items)):\n",
    "            remove_tag = re.compile('<.*?>')\n",
    "            title = re.sub(remove_tag, \"\", items[item_index]['title'])\n",
    "            link = items[item_index]['link']\n",
    "            description = re.sub(remove_tag, '', items[item_index]['description'])\n",
    "            # web_df.loc[idx]를 사용하여 데이터프레임에 검색 결과를 저장합니다. idx 변수는 저장된 데이터의 개수를 세는 변수\n",
    "            web_df.loc[idx] = [datetime, title, link, description]\n",
    "            idx += 1        \n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "web_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "client_id = \"xUCzXK76sez26412vcLf\"\n",
    "client_secret = \"oCZNcdIe3A\"\n",
    "\n",
    "query = urllib.parse.quote(input(\"검색 질의: \"))\n",
    "\n",
    "idx = 0\n",
    "display = 100\n",
    "start = 1\n",
    "end = 1000\n",
    "sort = \"sim\"\n",
    "\n",
    "news_df = pd.DataFrame(columns=('Title','Original Link','Link','Description','Publication Date'))\n",
    "\n",
    "for start_index in range(start, end, display):\n",
    "\n",
    "    url = \"https://openapi.naver.com/v1/search/news?query=\" + query \\\n",
    "    + \"&display=\" + str(display) \\\n",
    "    + \"&start=\" + str(start_index) \\\n",
    "    + \"&sort=\" + sort\n",
    "    \n",
    "    # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        response_dict = json.loads(response_body.decode('utf-8'))\n",
    "        items = response_dict['items']\n",
    "        for item_index in range(0,len(items)):\n",
    "            remove_tag = re.compile('<.*?>')\n",
    "            title = re.sub(remove_tag, \"\", items[item_index]['title'])\n",
    "            original_link = items[item_index]['originallink']\n",
    "            link = items[item_index]['link']\n",
    "            description = re.sub(remove_tag, '', items[item_index]['description'])\n",
    "            pub_date = items[item_index]['pubDate']\n",
    "            news_df.loc[idx] = [title, original_link, link, description, pub_date]\n",
    "            idx += 1        \n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['Original Link']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60cfe6",
   "metadata": {},
   "source": [
    "### OpenWeatherMap 날씨정보\n",
    "\n",
    "https://home.openweathermap.org/users/sign_up\n",
    "\n",
    "[사용방법]\n",
    "\n",
    "- https://openweathermap.org/api 사이트에서 Current Weather data에 대한 API doc 내용을 파악\n",
    "- OpenWeatherMap 홈페이지에서 회원가입\n",
    "- 회원가입 후 API Key를 발급. New Account 등록 후 API Keys라는 탭에서 API Key 확인 가능\n",
    "- 발급받은 API Key를 사용하여 API를 호출\n",
    "- 기본적으로 유료 사이트이지만 현재 날씨, 5일까지의 날씨는 무료로 사용할 수 있음(단 1분에 60번만 호출 가능)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
