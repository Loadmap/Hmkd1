{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 검색 API 예제 - 블로그 검색\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "# client_id와 client_secret 변수에는 네이버에서 제공하는 클라이언트 ID와 클라이언트 시크릿 값이 저장\n",
    "client_id = \"YOUR_CLIENT_ID\"\n",
    "client_secret = \"YOUR_CLIENT_SECRET\"\n",
    "# urllib.parse.quote() 함수를 사용하여 검색어에 대한 URL 인코딩을 수행\n",
    "encText = urllib.parse.quote(\"검색할 단어\")\n",
    "# url 변수에는 검색어를 포함한 검색 API의 URL이 저장되어 있습니다. 이때 검색 결과 형식을 JSON or XML로 설정\n",
    "url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # JSON 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # XML 결과\n",
    "\n",
    "# urllib.request.Request() 함수를 사용하여 API에 대한 요청(Request) 객체를 생성\n",
    "request = urllib.request.Request(url)\n",
    "# add_header() 함수를 사용하여 클라이언트 ID와 클라이언트 시크릿 값을 요청 헤더에 포함\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "# urllib.request.urlopen() 함수를 사용하여 요청 객체를 전송하고, API에서 반환한 응답(Response) 객체를 받아옴\n",
    "response = urllib.request.urlopen(request)\n",
    "# response.getcode() 함수를 사용하여 HTTP 응답 코드를 확인\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    # response_body.decode('utf-8') 함수를 사용하여 문자열 형태로 디코딩\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85989f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "xml = response_body.decode('utf-8')\n",
    "bs = BeautifulSoup(xml,'lxml')\n",
    "bs.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "texts = str(bs)\n",
    "# texts = re.sub(r'<[^>]*>','',texts)\n",
    "texts = re.sub(r'<.*?>','',texts) # <.*?> 패턴은 꺽쇠 괄호 사이에 있는 최소한의 문자열을 매칭시키는 패턴\n",
    "texts = re.findall(r'[a-zA-Z0-9가-힣]+', texts)\n",
    "print(' '.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "client_id = \"xUCzXK76sez26412vcLf\"\n",
    "client_secret = \"oCZNcdIe3A\"\n",
    "query = urllib.parse.quote(input('검색 질의 : '))\n",
    "\n",
    "url = \"https://openapi.naver.com/v1/search/webkr?query=\" + query # json 결과\n",
    "\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "idx =0\n",
    "web_df = pd.DataFrame(columns=('title','link','description'))\n",
    "\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    response_dict = json.loads(response_body.decode('utf-8'))\n",
    "    \n",
    "    items = response_dict['items']\n",
    "    \n",
    "    for item_index in range(0,len(items)):\n",
    "        remove_tag = re.compile('<.*?>')\n",
    "        title = re.sub(remove_tag, \"\", items[item_index]['title'])\n",
    "        link = items[item_index]['link']\n",
    "        description = re.sub(remove_tag, '',items[item_index]['description'] )\n",
    "        web_df.loc[idx] = [title, link, description]\n",
    "        idx += 1\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "    \n",
    "web_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "client_id = \"xUCzXK76sez26412vcLf\"\n",
    "client_secret = \"oCZNcdIe3A\"\n",
    "\n",
    "query = urllib.parse.quote(input(\"검색 질의: \"))\n",
    "# encText = urllib.parse.quote(\"빅데이터\") # utf-8 형태로 인코딩\n",
    "idx = 0\n",
    "display = 100\n",
    "start = 1\n",
    "end = 1000\n",
    "\n",
    "web_df = pd.DataFrame(columns=('Datetime','Title','Link','Description'))\n",
    "\n",
    "# for 문을 사용하여 검색 결과를 한 번에 display개씩 가져오는 것을 반복하며, \n",
    "# start_index 변수에는 현재 검색 결과 중 첫 번째 인덱스가 저장\n",
    "for start_index in range(start, end, display):\n",
    "    \n",
    "# url 변수에는 검색어와 검색 결과 개수, 시작 인덱스 등이 포함된 검색 API의 URL이 저장\n",
    "    url = \"https://openapi.naver.com/v1/search/webkr?query=\" + query \\\n",
    "    + \"&display=\" + str(display) \\\n",
    "    + \"&start=\" + str(start_index)\n",
    "     \n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        response_dict = json.loads(response_body.decode('utf-8'))\n",
    "        # response_dict에서 items 키 값을 추출하고, 이를 반복하며 title, link, description 등의 정보를 추출\n",
    "        items = response_dict['items']\n",
    "        \n",
    "        for item_index in range(0,len(items)):\n",
    "            remove_tag = re.compile('<.*?>')\n",
    "            title = re.sub(remove_tag, \"\", items[item_index]['title'])\n",
    "            link = items[item_index]['link']\n",
    "            description = re.sub(remove_tag, '', items[item_index]['description'])\n",
    "            # web_df.loc[idx]를 사용하여 데이터프레임에 검색 결과를 저장합니다. idx 변수는 저장된 데이터의 개수를 세는 변수\n",
    "            web_df.loc[idx] = [datetime, title, link, description]\n",
    "            idx += 1        \n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "web_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "client_id = \"xUCzXK76sez26412vcLf\"\n",
    "client_secret = \"oCZNcdIe3A\"\n",
    "\n",
    "query = urllib.parse.quote(input(\"검색 질의: \"))\n",
    "\n",
    "idx = 0\n",
    "display = 100\n",
    "start = 1\n",
    "end = 1000\n",
    "sort = \"sim\"\n",
    "\n",
    "news_df = pd.DataFrame(columns=('Title','Original Link','Link','Description','Publication Date'))\n",
    "\n",
    "for start_index in range(start, end, display):\n",
    "\n",
    "    url = \"https://openapi.naver.com/v1/search/news?query=\" + query \\\n",
    "    + \"&display=\" + str(display) \\\n",
    "    + \"&start=\" + str(start_index) \\\n",
    "    + \"&sort=\" + sort\n",
    "    \n",
    "    # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        response_dict = json.loads(response_body.decode('utf-8'))\n",
    "        items = response_dict['items']\n",
    "        for item_index in range(0,len(items)):\n",
    "            remove_tag = re.compile('<.*?>')\n",
    "            title = re.sub(remove_tag, \"\", items[item_index]['title'])\n",
    "            original_link = items[item_index]['originallink']\n",
    "            link = items[item_index]['link']\n",
    "            description = re.sub(remove_tag, '', items[item_index]['description'])\n",
    "            pub_date = items[item_index]['pubDate']\n",
    "            news_df.loc[idx] = [title, original_link, link, description, pub_date]\n",
    "            idx += 1        \n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['Original Link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9c17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
